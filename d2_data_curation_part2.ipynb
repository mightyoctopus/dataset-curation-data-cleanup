{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b036031e-c57c-47a1-b228-65076e8d2427",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Volumes/VTG/Dev/C_5/Projects/week6/data_curation-optimization/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import random\n",
    "from dotenv import load_dotenv\n",
    "from huggingface_hub import login\n",
    "from datasets import load_dataset, Dataset, DatasetDict\n",
    "import matplotlib.pyplot as plt\n",
    "from collections import Counter, defaultdict\n",
    "import numpy as np \n",
    "import pickle\n",
    "\n",
    "### Internal classes\n",
    "from loaders import ItemLoader\n",
    "from items import Item "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff63bd3f-660d-4cee-bca3-fe50a04267ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f730153a-36a5-43b7-b161-c800d8f72c73",
   "metadata": {},
   "outputs": [],
   "source": [
    "load_dotenv()\n",
    "\n",
    "OPENAI_API_KEY = os.getenv(\"OPENAI_API_KEY\")\n",
    "ANTHROPIC_API_KEY = os.getenv(\"ANTHROPIC_API_KEY\")\n",
    "HF_TOKEN_KEY = os.getenv(\"HF_TOKEN\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57368f7e-e305-43a7-8c6f-eab8a8fa1c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Note: Environment variable`HF_TOKEN` is set and is the current active token independently from the token you've just configured.\n"
     ]
    }
   ],
   "source": [
    "login(HF_TOKEN_KEY, add_to_git_credential=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "be4a9983-0e9b-486b-ba03-80524cdf344f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: Electronics\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                            | 0/162 [00:00<?, ?it/s]None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "100%|██████████████████████████████████████████████████████████████████| 162/162 [02:40<00:00,  1.01it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Electronics with 477,816 datapoints in 2.8 mins\n",
      "How much does this cost to the nearest dollar?\n",
      "\n",
      "Digi-Tatoo Decal Skin Compatible With MacBook Pro 13 inch (Model A2338/ A2289/ A2251) - Protective and Decorative Full Body Laptop Skin Decal Sticker, Anti-Scratch Vinly Skin Sticker Wrap  Fresh Marble\n",
      "WARNING  Please IDENTIFY MODEL NUMBER on the bottom of your Macbook. Only fits for model A2338/ A2289/ A2251 (Macbook Pro 13\" w/ Touch Bar, release). Extra Care Yet Not Bulky. Our skin is capable of protecting the surface of your Macbook from daily scratches, dust, oil, water and fingerprint. Your Macbook remains fresh some years later. Elegant Style. Our stylish design and printing tech give your Macbook a 360 degree decorative and\n",
      "\n",
      "Price is $20.00\n",
      "477816\n"
     ]
    }
   ],
   "source": [
    "items = ItemLoader(\"Electronics\").load()\n",
    "\n",
    "print(items[0].prompt)\n",
    "\n",
    "print(len(items))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86312abd-214a-4cb9-aec0-587b1223cfcc",
   "metadata": {},
   "source": [
    "## Scale Up -- All Different Categories Into One List"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "711fa219-78b6-4113-990b-5e47a1b34d66",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_names = [\n",
    "    \"All_Beauty\", \"Arts_Crafts_and_Sewing\", \"Cell_Phones_and_Accessories\", \n",
    "    \"Electronics\", \"Gift_Cards\", \"Handmade_Products\", \"Industrial_and_Scientific\", \n",
    "    \"Musical_Instruments\", \"Toys_and_Games\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a284673-1680-4fa8-b321-859b26a92b7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading dataset: All_Beauty\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                             | 0/12 [00:00<?, ?it/s]None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "100%|████████████████████████████████████████████████████████████████████| 12/12 [00:05<00:00,  2.18it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed All_Beauty with 6,522 datapoints in 0.1 mins\n",
      "Loading dataset: Arts_Crafts_and_Sewing\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                             | 0/81 [00:00<?, ?it/s]None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "100%|████████████████████████████████████████████████████████████████████| 81/81 [01:13<00:00,  1.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Completed Arts_Crafts_and_Sewing with 331,924 datapoints in 1.3 mins\n",
      "Loading dataset: Cell_Phones_and_Accessories\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                                            | 0/129 [00:00<?, ?it/s]None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      "None of PyTorch, TensorFlow >= 2.0, or Flax have been found. Models won't be available and only tokenizers, configuration and file/data utilities can be used.\n",
      " 84%|███████████████████████████████████████████████████████▊          | 109/129 [01:41<00:14,  1.41it/s]"
     ]
    }
   ],
   "source": [
    "items = [] \n",
    "for dataset_name in dataset_names: \n",
    "    loader = ItemLoader(dataset_name)\n",
    "    items.extend(loader.load())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "809aa2ee-319b-4d57-8dba-d0942728e08a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Grand Total of {len(items):,} Items.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b54c555f-a540-4811-bd6f-7c587c15366e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Count tokens -- Avr and highest out of the all items \n",
    "tokens = [item.token_count for item in items]\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.title(f\"Avr Tokens: {sum(tokens) / len(tokens):.2f} | Highest Tokens: {max(tokens)}\")\n",
    "plt.xlabel(\"Tokens\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.hist(tokens, rwidth=0.7, color=\"purple\", bins = range(150, 200, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95afd43d-3b68-4568-ba41-378c7a96144e",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Price distribution out of the all items\n",
    "### (Avr price and highest)\n",
    "\n",
    "prices = [item.price for item in items]\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.title(f\"Avr Price: \\\\${sum(prices) / len(prices):,.2f} | Highest Price: ${max(prices):,}\")\n",
    "plt.xlabel(\"Price\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.hist(prices, rwidth=0.7, color=\"C8\", bins=range(0, 1000, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2f6315e-34e7-4de0-ae11-5224c4cff493",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(items[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "768ecbfd-177d-47d3-99bd-dbc0f8c603f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_categories = [item.category for item in items]\n",
    "\n",
    "counter = Counter(raw_categories)\n",
    "\n",
    "### Category with the highest number of items\n",
    "top_category = counter.most_common(1)\n",
    "\n",
    "### keys and values - keys: categories | values: item counts\n",
    "# key_list = [k for k, v in counter.items()]\n",
    "# value_list = [v for k, v in counter.items()]\n",
    "\n",
    "categories, counts = zip(*counter.items())\n",
    "\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.bar(categories, counts, color=\"goldenrod\")\n",
    "plt.title(f\"Avr Num of Items: {round(counter.total() / len(categories))} | Highest Products Listed: {top_category[0][0]} - {top_category[0][1]} items\")\n",
    "plt.xlabel(\"Categories\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.xticks(rotation=10, ha=\"right\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20c35776-f608-4400-913d-2fd3c673bda6",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(items[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9c07650-fb4c-4ee9-a714-4fdda829f1ae",
   "metadata": {},
   "source": [
    "## Objective\n",
    "\n",
    "Craft a dataset which is more balanced in terms of prices. Less heavily scewed to cheap items, with an average that's higher than $60. Try to balance out the categories - fewer Automotive items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6bd1329b-7be1-4f99-9c2d-1dc091f7c34d",
   "metadata": {},
   "outputs": [],
   "source": [
    "slots = defaultdict(list)\n",
    "for item in items: \n",
    "    slots[round(item.price)].append(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7642f59b-338d-460e-b722-9978e8e858b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dataset called \"sample\" which tries to more evenly take from the range of prices\n",
    "# And gives more weight to items from categories other than Automotive\n",
    "# Set random seed for reproducibility\n",
    "\n",
    "np.random.seed(42)\n",
    "random.seed(42)\n",
    "\n",
    "### samples list with data sorted by lower price to higher order: range(1, 1000)\n",
    "samples = []\n",
    "\n",
    "for i in range(1, 1000): \n",
    "    slot = slots[i]\n",
    "    if i >= 240:\n",
    "        samples.extend(slot) \n",
    "    elif len(slot) <= 1200: \n",
    "        samples.extend(slot) \n",
    "    else: \n",
    "        weights = np.array([1 if item.category == \"Electronics\" else 5 for item in slot])\n",
    "        weights = weights / sum(weights) \n",
    "        selected_indices = np.random.choice(len(slot), size=1200, replace=False, p=weights) \n",
    "        selected = [slot[i] for i in selected_indices]\n",
    "        samples.extend(selected)\n",
    "        \n",
    "print(f\"There are {len(samples):,} items in the sample\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e3d61c73-b2f0-41e7-b89b-68ddae210e70",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plot the distribution of prices in sample\n",
    "\n",
    "prices = [float(item.price) for item in samples]\n",
    "plt.figure(figsize=(15, 10))\n",
    "plt.title(f\"Avg {sum(prices)/len(prices):.2f} and highest {max(prices):,.2f}\\n\")\n",
    "plt.xlabel('Price ($)')\n",
    "plt.ylabel('Count')\n",
    "plt.hist(prices, rwidth=0.7, color=\"darkblue\", bins=range(0, 1000, 10))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3786bb7-c6c7-43fa-9b00-a083ce947eee",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Category Counter \n",
    "\n",
    "categories = [item.category for item in samples]\n",
    "\n",
    "category_counter = Counter(categories) \n",
    "\n",
    "### Separate categories and counts \n",
    "cats, counts = zip(*category_counter.items())\n",
    "### Category with the highest counts\n",
    "highest_key = category_counter.most_common(1)\n",
    "\n",
    "### Bar Chart:\n",
    "plt.figure(figsize=(15, 6))\n",
    "plt.bar(cats, counts, color=\"lightgreen\")\n",
    "plt.title(f\"Avr Counts of Categories: {sum(counts) / len(counts):.2f} | Highest Counts: {max(counts)}({highest_key[0][0]})\")\n",
    "plt.xlabel(\"Categories\")\n",
    "plt.ylabel(\"Counts\")\n",
    "plt.xticks(rotation=30, ha=\"right\")\n",
    "\n",
    "\n",
    "### Add labels on top of each bar \n",
    "for i, v in enumerate(counts): \n",
    "    plt.text(i, v, f\"{v:,}\", ha=\"center\", va=\"bottom\")\n",
    "\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "080b9d59-7afe-44cf-a4f1-f15e3f281f90",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Pie chart\n",
    "\n",
    "plt.figure(figsize=(12, 10))\n",
    "plt.pie(counts, labels=cats, autopct='%1.0f%%', startangle=90)\n",
    "\n",
    "### Add a circle at the center to create a donut chart (optional)\n",
    "centre_circle = plt.Circle((0,0), 0.70, fc='white')\n",
    "fig = plt.gcf()\n",
    "fig.gca().add_artist(centre_circle)\n",
    "plt.title('Categories')\n",
    "\n",
    "### Equal aspect ratio ensures that pie is drawn as a circle\n",
    "plt.axis('equal')  \n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "22701eef-70ca-44f0-8f6a-63eaefb8c66a",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Correlation between text verbosity and price \n",
    "\n",
    "### To Check:\n",
    "### if high-end products having longer, more detailed descriptions \n",
    "### or cheap products having short, minimal text.\n",
    "\n",
    "\n",
    "sizes = [len(item.prompt) for item in samples]\n",
    "prices = [item.price for item in samples] \n",
    "\n",
    "plt.figure(figsize=(15, 8))\n",
    "plt.scatter(sizes, prices, s=0.2, color=\"red\")\n",
    "\n",
    "plt.title(\"Is there a simple correlation?\")\n",
    "plt.xlabel(\"Text Length\")\n",
    "plt.ylabel(\"Price\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b12d76f-dda3-4da8-8431-38159187bee8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def report(item): \n",
    "    prompt = item.prompt \n",
    "    tokens = Item.tokenizer.encode(item.prompt)\n",
    "    print(\"PROMPT:\\n\", prompt)\n",
    "    print(\"\\n\")\n",
    "    print(\"Last 10 Tokens:\\n\",tokens[-10:])\n",
    "    print(\"\\n\")\n",
    "    print(\"Last 10 Decoded:\\n\",Item.tokenizer.batch_decode(tokens[-10:]))\n",
    "\n",
    "print(report(samples[222382]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e086c601-47f4-42b0-850a-5df38fc58bef",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
